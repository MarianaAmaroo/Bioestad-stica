---
title: "Alzheimer Data Analysis"
format: html
editor: visual
---

```{r}
#| code-fold: true
#| label: load-packages
#| warning: false
#| message: false


library(tidyverse)
library(ggthemes)
library(RColorBrewer)
library(plotly)
library(pheatmap)
library(corrplot)
library(plotrix)
library(tastypie)

library(gplots)
library(ggmosaic)
library(treemapify)
library(ggridges)
library(ggalluvial)
library(scatterPlotMatrix)

library(readxl)
library(writexl)

library(kableExtra)
library(multcomp)
library(agricolae)
library(factoextra)
library(FactoMineR)

```

# Cargamos el conjunto de datos

```{r}
ruta_archivo <- file.choose()
print(ruta_archivo)

```

```{r}
#| code-fold: true

datos <-  read_csv("C:\\Users\\52462\\OneDrive\\Documentos\\Bioestadistica\\Bioestad-stica\\alzheimer.csv")

glimpse(datos)
datos$Group <- factor(datos$Group)
datos$M_F <- factor(datos$M_F)


```

# Resumen estadístico

```{r}
#| code-fold: true

summary(datos)

```

# Distribución de variables cuantitativas

## Histogramas

```{r}
#| code-fold: true


num_var <- dplyr::select(datos, where(is.numeric)) |> names() 

for (hvar in num_var) {
grafica <- ggplot(datos)+
      geom_density(aes(eval(as.name(hvar)), fill=Group), alpha=0.5, color='gray')+ 
        labs(x=hvar)+
        scale_fill_colorblind()+
        theme_bw()
        print(grafica)
        
}



```

# Filtro de datos

```{r}
#| code-fold: true

datos <-  datos |> dplyr::select(-SES)
datos <- datos[complete.cases(datos), ]

```

# Distribución de variables cualitativas

## Gráficas de barras

```{r}
#| code-fold: true
barplot <- ggplot(datos) +
  geom_bar(aes(Group, fill=M_F), color="black") +
  labs(
    title = "Gráfica de barras",
    x = "Grupo", y = "Count",
    fill = "M_F"
  ) +
  scale_fill_colorblind()+
  theme_bw()+
  theme(
    #legend.position="top",
    #legend.position = c(.95, .95),
    #legend.justification = c("right", "top"),
    #legend.box.just = "right",
    legend.title = element_text(size=13, face="bold"),
    legend.text = element_text(size=13),
    plot.title = element_text(size=15, face="bold"),
    plot.subtitle = element_text(size=13),
    axis.text.x=element_text(size=12),
    axis.text.y=element_text(size=12),
    axis.title.x = element_text(face="bold", size=13),
    axis.title.y = element_text(face="bold", size=13)
  )

barplot


```

```{r}
#| code-fold: true
barplot <- ggplot(datos) +
  geom_bar(aes(M_F, fill=Group), color="black") +
  labs(
    title = "Gráfica de barras",
    x = "M_F", y = "Count",
    fill = "Grupo"
  ) +
  scale_fill_colorblind()+
  theme_bw()+
  theme(
    #legend.position="top",
    #legend.position = c(.95, .95),
    #legend.justification = c("right", "top"),
    #legend.box.just = "right",
    legend.title = element_text(size=13, face="bold"),
    legend.text = element_text(size=13),
    plot.title = element_text(size=15, face="bold"),
    plot.subtitle = element_text(size=13),
    axis.text.x=element_text(size=12),
    axis.text.y=element_text(size=12),
    axis.title.x = element_text(face="bold", size=13),
    axis.title.y = element_text(face="bold", size=13)
  )

barplot


```

### Alluvialplot

```{r}
#| code-fold: true


datos_alluvia <- datos |> dplyr::select(Group, M_F) |> 
  group_by(Group, M_F) |> 
  summarize(frequency = n(), .groups = "drop")

ggplot(datos_alluvia, aes(y = frequency, axis1 = Group, axis2 = M_F)) +
  geom_alluvium(aes(fill = Group), width = 1/3, color = "black") +
  geom_stratum(width = 1/3, fill = "black", color = "grey") +
  geom_text(stat = "stratum", aes(label = after_stat(stratum)), color = "white", size = 3) +
  scale_x_discrete(limits = c("Grupo", "M_F"), expand = c(.05, .05)) +
  scale_fill_brewer(type = "qual", palette = "Dark2") + 
  theme_minimal()

```

# Heatmap

```{r}
#| code-fold: true



data_matrix <- datos |> dplyr::select(Age:ASF) |> as.matrix()
dm_dim <- dim(data_matrix)
rownames(data_matrix) <- paste("ID", 1:dm_dim[1], sep="_")


row_annot <- dplyr::select(datos, Group, M_F) |> as.data.frame()
rownames(row_annot) <- paste("ID", 1:dm_dim[1], sep="_")


mapa <- pheatmap(data_matrix, 
         border_color = NA, 
         scale = "column",
         clustering_distance_rows = "euclidean", 
         cutree_rows = 5,
         treeheight_col=10,
         clustering_distance_cols = "euclidean", 
         clustering_method = "ward.D2", 
         #color= hcl.colors(10, "Spectral"),
         #breaks = c(-3, 0, 3, 6, 9, 12, 15),
         drop_levels = TRUE,
         show_colnames = T, 
         show_rownames = F,
         annotation_row = row_annot)
         
         #,
         #annotation_colors = cond_color)

mapa

#ggsave("heatmap_1.jpg", mapa, scale=1, dpi = 320)
```

## Correlación

```{r}
#| code-fold: true

data_num <- dplyr::select(datos, where(is.numeric))
#data_num <- data_num[complete.cases(data_num), ]  
cor_mat <- cor(data_num)
cor_mat
```

```{r}
#| code-fold: true

pheatmap(cor_mat)
corrplot(cor_mat)
corrplot(cor_mat, method = "color")
corrplot(cor_mat, method = "color", order = "AOE")
corrplot(cor_mat, method = "color", order = "FPC", type="lower")
```

# Relación entre variables numéricas y categóricas

Previamente ya habíamos realizado las gráficas de densidad por especie para cada variable numérica.

### Boxplots

```{r}
#| code-fold: true


num_var <- dplyr::select(datos, where(is.numeric)) |> names() 

for (val_y in num_var) {
  box_graf <- ggplot(datos)+
    geom_boxplot(aes(x=Group, y=eval(as.name(val_y)), color = Group), show.legend = TRUE)+
    geom_jitter(aes(x=Group, y=eval(as.name(val_y)) ), color="firebrick", alpha=0.5)+
    stat_summary(aes(x=Group, y=eval(as.name(val_y))),fun.y=mean, geom="point", shape=20, size=5, color="red", fill="red") +
    labs(y=val_y)+
    theme_bw()
  
  print(box_graf)
}





```

# PCA

## Preparación de datos

Conservar observaciones completas de las variables numéricas.

```{r}
#| code-fold: true

datos_numeric <- datos |> dplyr::select(Age:ASF)

```

## Resultados

::: panel-tabset
### Eigenvalores y varianzas

```{r}
#| code-fold: true



PC_total <- prcomp(datos_numeric, scale.=TRUE, center=TRUE)

eig_total <- get_eigenvalue(PC_total)
eig_tabla <- data.frame(PC=paste0("PC",1:dim(eig_total)[1]), 
                        Eigenvalor=round(eig_total$eigenvalue,3), 
                        Varianza=round(eig_total$variance.percent,2), 
                        Var_acu=round(eig_total$cumulative.variance.percent,2))

kable(eig_tabla, align = "c", col.names = c("Componente", "Eigenvalor", "% varianza", "% varianza acumulada")) %>% kable_styling(c("striped", "hover"), full_width = F)%>% scroll_box(width="100%", height="300px", fixed_thead = TRUE)
```

### Scree plot

```{r}
#| code-fold: true
fviz_eig(PC_total, addlabels = TRUE)
```

### Coeficientes (Loadings)

```{r}
#| code-fold: true
PC_coef <-data.frame(PC_total$rotation)
kable(PC_coef, align = "c") %>% kable_styling(c("striped", "hover"), full_width = F)%>% scroll_box(width="100%", height="300px", fixed_thead = TRUE)
```

### Contribución variables

```{r}
#| code-fold: true
fviz_pca_var(PC_total, col.var = "contrib", gradient.cols=c("#1627dc", "#ffb600", "#ff2e16"))
```

### Contribución PC1

```{r}
#| code-fold: true
fviz_contrib(PC_total, "var", axes = 1)
```

### Contribución PC2

```{r}
#| code-fold: true
fviz_contrib(PC_total, "var", axes = 2)
```
:::

## Proyecciones

::: panel-tabset
### Biplot

```{r}
#| code-fold: true
fviz_pca_biplot(PC_total,
                geom.ind = "point",
                fill.ind = datos$Group,
                pointshape = 21 ,
                pointsize = 2,
                alpha.ind=0.6,
                col.var = "black",
                #palette= ,
                label= "var",
                repel = TRUE   
  )
```

### Proyección

```{r}
#| code-fold: true
proy_scores <- fviz_pca_ind(PC_total,
             pointsize = 2,
             habillage =datos$Group,
             #addEllipses = TRUE,
             label= "var",
            repel = TRUE 
  )

ggplotly(proy_scores)
```
:::

# Agrupamiento jerárquico

Se estandarizan los datos por columnas.

```{r}
sd.data <- scale(datos_numeric)
row.names(sd.data) <- paste("ID", 1:nrow(sd.data), sep="_")
```

## Distancia Euclidiana

```{r}
#| code-fold: true

dist.eucl <- dist(sd.data)
dist.eucl_matrix <- as.matrix(dist.eucl)
dist.eucl_plot <- fviz_dist(dist.eucl, lab_size = 6)
dist.eucl_plot

```

## Ward.D2

```{r}
#| code-fold: true
#| warning: false

euc_ward2_hc <- hclust(dist.eucl, method = "ward.D2")
fviz_dend(euc_ward2_hc, k=3, cex=0.5, k_colors = "jco", rect=TRUE, rect_border= "jco", rect_fill = TRUE, labels_track_height=0.25)
```

Se proyecta en el subespacio generado por las dos primeras componentes principales:

```{r}
#| code-fold: true

grp_euc_ward2 <- cutree(euc_ward2_hc, k=3)
fviz_cluster(list(data= sd.data, cluster= grp_euc_ward2), geom="point",
             palette = "jco", ellipse.type = "convex", show.clust.cent = FALSE, ggtheme = theme_bw())
```

:::

# K-medias

Se lleva a cabo el agrupamiento de K-medias con K=3.

```{r}
#| code-fold: true

km.3 <- kmeans(sd.data, 3, nstart = 25)
fviz_cluster(km.3, data = sd.data, palette= "jco", ellipse.type = "euclid", star.plot=TRUE, geom="point",  ggtheme=theme_bw())


```

# LDA

```{r}
#| code-fold: true

data_lda <- datos |> dplyr::select(-M_F)

lda_tx <- lda(Group~.,data=data_lda)
lda_coef <- data.frame(varnames=names(data_lda[, -1]), coef(lda_tx))
#lda_coef$valor <- gsub("<", "", datos_prev_num$valor)
prediction_group <- lda_tx |> predict(data_lda)
lda_acc <-  mean(prediction_group$class==unname(as_vector(data_lda$Group))) 
lda_data <- cbind(data_lda, prediction_group$x, prediction_group$posterior, pred_group= prediction_group$class)

```

```{r}
#| code-fold: true

lda_data_graf <- lda_data
lda_plot <- ggplot(lda_data_graf, aes(x=LD1, y=LD2))+
    geom_point(aes(fill=Group), shape=21, color="black", size=5)+
  #  scale_fill_manual(values = my_colors)+
    theme_light()+
  #geom_text(data=data.scores,aes(x=NMDS1,y=NMDS2,label=site),size=6,vjust=0) + 
  scale_fill_manual(values=c("Converted"="darkblue","Demented"="firebrick", "Nondemented" = "yellowgreen"))+
  labs(x= "LD1", 
       y= "LD2", fill=" ")+
    #theme_bw()+
    theme(
      plot.title = element_text(size=14),
      axis.text.x=element_text(size=14),
      axis.text.y=element_text(size=14),
      axis.title.x = element_text(face="bold", size=15),
      axis.title.y = element_text(face="bold", size=15),
      legend.text = element_text(size=15),
      legend.background  = element_rect(colour = "transparent", fill = "transparent")
    )

ggplotly(lda_plot)

#ggsave("LDA_Alzheimer.jpg", lda_plot, width = 190, height = 160, units="mm", scale=1, dpi=320)
```

```{r}
# Cargar datos y limpiar valores faltantes
datos <- na.omit(datos)

# Dividir datos en entrenamiento y prueba
set.seed(42)
train_indices <- sample(1:nrow(datos), size = 0.8 * nrow(datos))
train_data <- datos[train_indices, ]
test_data <- datos[-train_indices, ]

# Ajustar modelo lineal (usando todas las variables predictoras excepto CDR)
modelo <- lm(CDR ~ Age + EDUC + MMSE + eTIV + nWBV + ASF, data = train_data)

# Realizar predicciones en el conjunto de prueba
y_pred <- predict(modelo, test_data)

# Valores reales del conjunto de prueba
y_test <- test_data$CDR

# Niveles válidos de CDR
valid_cdr_levels <- c(0.0, 0.5, 1.0, 2.0, 3.0)

# Redondear predicciones al nivel válido más cercano
round_to_valid <- function(value, valid_levels) {
  valid_levels[which.min(abs(valid_levels - value))]
}

y_pred_corrected <- sapply(y_pred, round_to_valid, valid_cdr_levels)

# Comparar valores reales y predichos
comparison_table <- data.frame(
  Actual = y_test,
  Predicted = y_pred_corrected,
  Correct = y_test == y_pred_corrected
)

# Calcular precisión
accuracy_corrected <- mean(comparison_table$Correct)
print(paste("Precisión:", accuracy_corrected))
print(head(comparison_table))


```

Actual: Los valores reales de CDR en el conjunto de prueba. Predicted: Los valores predichos redondeados al nivel válido más cercano. Correct: Si la predicción coincide con el valor real. \## ¿Cómo usar estos resultados? Precisión: Evalúa qué tan bien funciona tu modelo. Tabla de comparación: Identifica casos donde las predicciones fallaron. Casos problemáticos: Analiza los registros donde Correct = FALSE para investigar las características que llevaron al error.

## Buscar datos atipicos

```{r}
# Filtrar casos incorrectos
incorrect_cases <- comparison_table[comparison_table$Correct == FALSE, ]

# Mostrar los casos incorrectos
print("Casos con predicciones incorrectas:")
print(incorrect_cases)

# Analizar patrones en las variables del conjunto de prueba para estos casos
discrepancias <- test_data[rownames(incorrect_cases), ]

# Resumen estadístico de las discrepancias
print("Resumen de discrepancias:")
summary(discrepancias)

# Ejemplo: Distribución de CDR en los casos incorrectos
library(ggplot2)
ggplot(discrepancias, aes(x = CDR)) +
  geom_bar(fill = "tomato", color = "black") +
  theme_minimal() +
  labs(
    title = "Distribución de CDR en predicciones incorrectas",
    x = "CDR Real",
    y = "Frecuencia"
  )

```

## Datos incorrectos LD

```{r}
#Crear un conjunto de datos con los casos incorrectos
ld_incorrectos <- test_data[rownames(incorrect_cases), ]

# Dividir nuevamente en entrenamiento y prueba (para LD)
set.seed(123)
train_indices_ld <- sample(1:nrow(ld_incorrectos), size = 0.8 * nrow(ld_incorrectos))
train_data_ld <- ld_incorrectos[train_indices_ld, ]
test_data_ld <- ld_incorrectos[-train_indices_ld, ]

# Ajustar un nuevo modelo lineal con los casos incorrectos
modelo_ld <- lm(CDR ~ Age + EDUC + MMSE + eTIV + nWBV + ASF, data = train_data_ld)

# Realizar predicciones con el nuevo modelo
y_pred_ld <- predict(modelo_ld, test_data_ld)
y_test_ld <- test_data_ld$CDR

# Redondear al nivel válido más cercano
y_pred_ld_corrected <- sapply(y_pred_ld, round_to_valid, valid_cdr_levels)

# Comparar valores reales y predichos en LD
comparison_table_ld <- data.frame(
  Actual = y_test_ld,
  Predicted = y_pred_ld_corrected,
  Correct = y_test_ld == y_pred_ld_corrected
)

# Calcular precisión del modelo LD
accuracy_ld <- mean(comparison_table_ld$Correct)

# Resultados
print(paste("Precisión en casos incorrectos (LD):", accuracy_ld))
print("Tabla de comparación para LD:")
print(head(comparison_table_ld))
```
## Análisis de importancia de las variables
```{r}
# Coeficientes del modelo original
coef(modelo)

# Coeficientes del modelo LD
coef(modelo_ld)

```
```{r}
# Mapa de calor de correlaciones
library(corrplot)

# Calcular matriz de correlaciones
cor_matrix <- cor(na.omit(datos[, c("Age", "MMSE", "eTIV", "nWBV", "ASF")])) 

# Visualizar la matriz de correlaciones
corrplot(cor_matrix, method = "color", addCoef.col = "black", 
         tl.col = "black", title = "Mapa de correlaciones")

```

